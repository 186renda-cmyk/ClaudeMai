import urllib.request
import json
import xml.etree.ElementTree as ET
import os

# ================= é…ç½®åŒºåŸŸ =================
# ç™¾åº¦ç«™é•¿å¹³å°æä¾›çš„ API æ¥å£åœ°å€
API_URL = "http://data.zz.baidu.com/urls?site=https://claudemai.top&token=MkpV4it8Aq1PaVbS"
SITEMAP_FILE = "sitemap.xml"
# ===========================================

def get_urls_from_sitemap():
    url_list = []
    try:
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ° sitemap.xml
        script_dir = os.path.dirname(os.path.abspath(__file__))
        sitemap_path = os.path.join(script_dir, SITEMAP_FILE)
        
        if not os.path.exists(sitemap_path):
            print(f"âŒ æ‰¾ä¸åˆ° sitemap æ–‡ä»¶: {sitemap_path}")
            return []
            
        tree = ET.parse(sitemap_path)
        root = tree.getroot()
        
        # å¤„ç† namespace
        # sitemap.xml é€šå¸¸æœ‰ namespace, ä¾‹å¦‚: {http://www.sitemaps.org/schemas/sitemap/0.9}
        namespace = ''
        if root.tag.startswith('{'):
            namespace = root.tag.split('}')[0] + '}'
            
        for url in root.findall(f'{namespace}url'):
            loc = url.find(f'{namespace}loc')
            if loc is not None and loc.text:
                url_list.append(loc.text.strip())
                
        print(f"ğŸ“„ ä» sitemap.xml æå–åˆ° {len(url_list)} ä¸ª URL")
        return url_list
    except Exception as e:
        print(f"âŒ è§£æ sitemap.xml å¤±è´¥: {str(e)}")
        return []

def submit_to_baidu():
    # åŠ¨æ€è·å– URL åˆ—è¡¨
    url_list = get_urls_from_sitemap()
    
    if not url_list:
        print("âŒ URL åˆ—è¡¨ä¸ºç©ºï¼Œåœæ­¢æäº¤")
        return

    print(f"ğŸš€ æ­£åœ¨å‘ç™¾åº¦æœç´¢èµ„æºå¹³å°æäº¤ {len(url_list)} ä¸ª URL...")
    
    # å‡†å¤‡æ•°æ®ï¼šæ¯è¡Œä¸€ä¸ª URL
    data = '\n'.join(url_list).encode('utf-8')
    
    try:
        req = urllib.request.Request(
            API_URL, 
            data=data, 
            headers={
                'Content-Type': 'text/plain',
                'User-Agent': 'curl/7.12.1',
                'Host': 'data.zz.baidu.com'
            }
        )

        with urllib.request.urlopen(req) as response:
            status_code = response.getcode()
            result = response.read().decode('utf-8')
            result_json = json.loads(result)

            if status_code == 200:
                print(f"âœ… æäº¤æˆåŠŸ!")
                print(f"   - æˆåŠŸæ¨é€æ•°é‡: {result_json.get('success', 0)}")
                print(f"   - å½“å¤©å‰©ä½™é¢åº¦: {result_json.get('remain', 'æœªçŸ¥')}")
                if 'not_same_site' in result_json:
                    print(f"   âš ï¸ æ³¨æ„: æœ‰ {len(result_json['not_same_site'])} ä¸ªé“¾æ¥éæœ¬ç«™é“¾æ¥")
                if 'not_valid' in result_json:
                    print(f"   âš ï¸ æ³¨æ„: æœ‰ {len(result_json['not_valid'])} ä¸ªé“¾æ¥ä¸åˆæ³•")
                
                print("--------------------------------")
                for url in url_list:
                    print(f"  - {url}")
                print("--------------------------------")
            else:
                print(f"âš ï¸ æäº¤å¯èƒ½é‡åˆ°é—®é¢˜ã€‚çŠ¶æ€ç : {status_code}")
                print(result)

    except urllib.error.HTTPError as e:
        print(f"âŒ HTTP é”™è¯¯: {e.code} {e.reason}")
        print(e.read().decode('utf-8'))
    except Exception as e:
        print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    submit_to_baidu()
